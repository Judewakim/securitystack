AWSTemplateFormatVersion: '2010-09-09'
Description: Enterprise Security Layer - Enables GuardDuty, Security Hub, CloudTrail, Config with optional conformance packs, centralized logging, alerting, gap remediation, and reporting. Single/multi-region support. Complies with SOC 2 (CC6.1, CC7.2) and ISO 27001 (A.9.2, A.12.4).

Parameters:
  DeploymentRegion:
    Type: String
    Default: us-east-1
    Description: Primary deployment region.
    AllowedPattern: ^[a-z]{2}-[a-z]+-[0-9]+$
  SingleRegionOnly:
    Type: String
    Default: false
    AllowedValues: [true, false]
    Description: Set to true for single-region CloudTrail (current region only). Default is multi-region (global coverage).
  ConformancePackOption:
    Type: String
    Default: Both
    AllowedValues: [Both, AWS-Foundational, CIS, None]
    Description: Select conformance packs for Config.
  OptOutGuardDuty:
    Type: String
    Default: false
    AllowedValues: [true, false]
  OptOutConfig:
    Type: String
    Default: false
    AllowedValues: [true, false]
  SNSEmails:
    Type: CommaDelimitedList
    Default: ''
    Description: Single email for alerts (optional; if empty, no alerts sent).
  ConfigS3BucketName:
    Type: String
    Description: Unique S3 bucket name for AWS Config logs (global unique).
    AllowedPattern: ^[a-z0-9][a-z0-9-]{2,62}[a-z0-9]$
  CloudTrailS3BucketName:
    Type: String
    Description: Unique S3 bucket name for CloudTrail logs (global unique).
    AllowedPattern: ^[a-z0-9][a-z0-9-]{2,62}[a-z0-9]$

Conditions:
  EnableMultiRegion: !Equals [!Ref SingleRegionOnly, false]
  EnableGuardDuty: !Equals [!Ref OptOutGuardDuty, false]
  EnableConfig: !Equals [!Ref OptOutConfig, false]
  EnableAWSFoundationalPack: !Or [!Equals [!Ref ConformancePackOption, Both], !Equals [!Ref ConformancePackOption, AWS-Foundational]]
  EnableCISPack: !Or [!Equals [!Ref ConformancePackOption, Both], !Equals [!Ref ConformancePackOption, CIS]]
  HasSNSEmails: !Not [!Equals [!Join ['', !Ref SNSEmails], '']]

Resources:
  ConfigLogBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref ConfigS3BucketName
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      LifecycleConfiguration:
        Rules:
          - Id: ComplianceLifecycle
            Status: Enabled
            Transitions:
              - StorageClass: STANDARD_IA
                TransitionInDays: 30
              - StorageClass: GLACIER
                TransitionInDays: 90
            ExpirationInDays: 365
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7
          - Id: NonCurrentVersions
            Status: Enabled
            NoncurrentVersionTransitions:
              - StorageClass: GLACIER
                TransitionInDays: 30
            NoncurrentVersionExpiration:
              NoncurrentDays: 365
      VersioningConfiguration:
        Status: Enabled
  CloudTrailLogBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref CloudTrailS3BucketName
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      LifecycleConfiguration:
        Rules:
          - Id: ComplianceLifecycle
            Status: Enabled
            Transitions:
              - StorageClass: STANDARD_IA
                TransitionInDays: 30
              - StorageClass: GLACIER
                TransitionInDays: 90
            ExpirationInDays: 365
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7
          - Id: NonCurrentVersions
            Status: Enabled
            NoncurrentVersionTransitions:
              - StorageClass: GLACIER
                TransitionInDays: 30
            NoncurrentVersionExpiration:
              NoncurrentDays: 365
      VersioningConfiguration:
        Status: Enabled
  ConfigBucketPolicy:
    Type: AWS::S3::BucketPolicy
    DependsOn: ConfigLogBucket
    Properties:
      Bucket: !Ref ConfigLogBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AWSConfigBucketAccess
            Effect: Allow
            Principal:
              Service: config.amazonaws.com
            Action:
              - s3:GetBucketAcl
              - s3:ListBucket
            Resource: !Sub arn:aws:s3:::${ConfigLogBucket}
          - Sid: AWSConfigObjectAccess
            Effect: Allow
            Principal:
              Service: config.amazonaws.com
            Action: s3:PutObject
            Resource: !Sub arn:aws:s3:::${ConfigLogBucket}/*
            Condition:
              StringEquals:
                's3:x-amz-acl': bucket-owner-full-control
          - Sid: LambdaAccess
            Effect: Allow
            Principal:
              AWS: !GetAtt LambdaExecutionRole.Arn
            Action:
              - s3:PutObject
              - s3:GetObject
              - s3:ListBucket
            Resource:
              - !Sub arn:aws:s3:::${ConfigLogBucket}
              - !Sub arn:aws:s3:::${ConfigLogBucket}/*
  CloudTrailBucketPolicy:
    Type: AWS::S3::BucketPolicy
    DependsOn: CloudTrailLogBucket
    Properties:
      Bucket: !Ref CloudTrailLogBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AWSCloudTrailAclCheck
            Effect: Allow
            Principal:
              Service: cloudtrail.amazonaws.com
            Action: s3:GetBucketAcl
            Resource: !Sub arn:aws:s3:::${CloudTrailLogBucket}
          - Sid: AWSCloudTrailWrite
            Effect: Allow
            Principal:
              Service: cloudtrail.amazonaws.com
            Action: s3:PutObject
            Resource: !Sub arn:aws:s3:::${CloudTrailLogBucket}/*
            Condition:
              StringEquals:
                's3:x-amz-acl': bucket-owner-full-control
  SecurityTrail:
    Type: AWS::CloudTrail::Trail
    DependsOn: CloudTrailBucketPolicy
    Properties:
      TrailName: SecurityStack-Trail
      S3BucketName: !Ref CloudTrailLogBucket
      IsLogging: true
      IsMultiRegionTrail: !If [EnableMultiRegion, true, false]
      EnableLogFileValidation: true
      IncludeGlobalServiceEvents: true
  ConfigRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal: { Service: config.amazonaws.com }
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWS_ConfigRole
      Policies:
        - PolicyName: ConfigS3Delivery
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:PutObjectAcl
                Resource: !Sub arn:aws:s3:::${ConfigLogBucket}/AWSLogs/${AWS::AccountId}/Config/*
              - Effect: Allow
                Action: s3:GetBucketAcl
                Resource: !Sub arn:aws:s3:::${ConfigLogBucket}
              - Effect: Allow
                Action: s3:GetObject
                Resource:
                  - arn:aws:s3:::solutions-reference/*
                  - arn:aws:s3:::config-bucket*
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal: { Service: lambda.amazonaws.com }
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SecurityAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - guardduty:CreateDetector
                  - guardduty:ListDetectors
                  - securityhub:EnableSecurityHub
                  - securityhub:DescribeHub
                  - securityhub:GetFindings
                  - config:PutConfigurationRecorder
                  - config:PutDeliveryChannel
                  - config:StartConfigurationRecorder
                  - config:DescribeConfigurationRecorders
                  - config:PutConformancePack
                  - config:DescribeConformancePacks
                  - config:GetConformancePackComplianceSummary
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:PutBucketEncryption
                  - s3:GetBucketEncryption
                  - s3:GetBucketAcl
                  - s3:PutBucketPublicAccessBlock
                Resource:
                  - !Sub arn:aws:s3:::${ConfigLogBucket}
                  - !Sub arn:aws:s3:::${ConfigLogBucket}/*
                  - !Sub arn:aws:s3:::${CloudTrailLogBucket}
                  - !Sub arn:aws:s3:::${CloudTrailLogBucket}/*
              - Effect: Allow
                Action: s3:ListAllMyBuckets
                Resource: '*'
              - Effect: Allow
                Action: s3:GetObject
                Resource:
                  - arn:aws:s3:::solutions-reference/*
                  - arn:aws:s3:::config-bucket*
              - Effect: Allow
                Action:
                  - iam:List*
                  - iam:Get*
                Resource: '*'
              - Effect: Allow
                Action: iam:PassRole
                Resource: !GetAtt ConfigRole.Arn
              - Effect: Allow
                Action:
                  - ec2:DescribeSecurityGroups
                  - ec2:DescribeInstances
                  - rds:DescribeDBInstances
                  - cloudtrail:DescribeTrails
                  - guardduty:ListDetectors
                Resource: '*'
  EnableServicesLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.12
      Timeout: 120
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import json

          def handler(event, context):
            response_data = {}
            print(f"EnableServicesLambda v2.0 started. Event: {json.dumps(event)}")
            # Version 2.0 - CloudTrail now handled by CloudFormation, not Lambda

            # BULLETPROOF: Always send response, no matter what
            try:
              # Validate event structure first
              if 'ResourceProperties' not in event:
                raise Exception("Missing ResourceProperties in event")

              props = event['ResourceProperties']
              if 'PrimaryRegion' not in props:
                raise Exception("Missing PrimaryRegion in ResourceProperties")

              region = props['PrimaryRegion']

              # GuardDuty with individual error handling
              try:
                if props['EnableGuardDuty'] == 'true':
                  gd = boto3.client('guardduty', region_name=region)
                  detectors = gd.list_detectors()['DetectorIds']
                  if not detectors:
                    gd.create_detector(Enable=True)
                  response_data[f'GuardDuty_{region}'] = 'Enabled'
                else:
                  response_data[f'GuardDuty_{region}'] = 'Skipped (OptOutGuardDuty=true)'
              except Exception as e:
                print(f"GuardDuty error: {str(e)}")
                response_data[f'GuardDuty_Error_{region}'] = str(e)

              # SecurityHub with individual error handling
              try:
                sh = boto3.client('securityhub', region_name=region)
                try:
                  sh.describe_hub()
                  response_data[f'SecurityHub_{region}'] = 'Already enabled'
                except sh.exceptions.InvalidAccessException:
                  sh.enable_security_hub()
                  response_data[f'SecurityHub_{region}'] = 'Enabled'
              except Exception as e:
                print(f"SecurityHub error: {str(e)}")
                response_data[f'SecurityHub_Error_{region}'] = str(e)

              # Config with individual error handling
              try:
                if props['EnableConfig'] == 'true':
                  cfg = boto3.client('config', region_name=region)
                  recorders = cfg.describe_configuration_recorders()['ConfigurationRecorders']
                  recorder_exists = any(rec['name'] == 'SecurityConfigRecorder' for rec in recorders)
                  if not recorder_exists:
                    cfg.put_configuration_recorder(
                      ConfigurationRecorder={
                        'name': 'SecurityConfigRecorder',
                        'roleARN': props['ConfigRoleArn'],
                        'recordingGroup': {'allSupported': True}
                      }
                    )
                    cfg.put_delivery_channel(
                      DeliveryChannel={
                        'name': 'SecurityDeliveryChannel',
                        's3BucketName': props['BucketName'],
                        'configSnapshotDeliveryProperties': {'deliveryFrequency': 'Six_Hours'}
                      }
                    )
                    cfg.start_configuration_recorder(ConfigurationRecorderName='SecurityConfigRecorder')
                    response_data[f'Config_{region}'] = 'Enabled'
                  else:
                    response_data[f'Config_{region}'] = 'Already exists'

                  if props['EnableAWSFoundational'] == 'true' and props['AWSFoundationalName'] != 'none':
                    try:
                      cfg.put_conformance_pack(
                        ConformancePackName=props['AWSFoundationalName'],
                        TemplateS3Uri=props['AWSFoundationalURI']
                      )
                      response_data[f'AWSFoundational_{region}'] = 'Enabled'
                    except cfg.exceptions.ResourceInUseException:
                      response_data[f'AWSFoundational_{region}'] = 'Already exists'
                    except Exception as conf_e:
                      print(f"Conformance pack error for AWSFoundational: {str(conf_e)}")
                      response_data[f'AWSFoundational_Error_{region}'] = str(conf_e)

                  if props['EnableCIS'] == 'true' and props['CISName'] != 'none':
                    try:
                      cfg.put_conformance_pack(
                        ConformancePackName=props['CISName'],
                        TemplateS3Uri=props['CISURI']
                      )
                      response_data[f'CIS_{region}'] = 'Enabled'
                    except cfg.exceptions.ResourceInUseException:
                      response_data[f'CIS_{region}'] = 'Already exists'
                    except Exception as conf_e:
                      print(f"Conformance pack error for CIS: {str(conf_e)}")
                      response_data[f'CIS_Error_{region}'] = str(conf_e)
                else:
                  response_data[f'Config_{region}'] = 'Skipped (OptOutConfig=true)'
              except Exception as e:
                print(f"Config error: {str(e)}")
                response_data[f'Config_Error_{region}'] = str(e)

              # Add Status field for CloudFormation Output reference
              response_data['Status'] = 'SUCCESS'
              print(f"Response data: {json.dumps(response_data)}")
              cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
              print("SUCCESS response sent to CloudFormation")

            except Exception as e:
              print(f"Top-level error: {str(e)}")
              try:
                cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e), 'Status': 'FAILED'})
                print("FAILED response sent to CloudFormation")
              except Exception as cfn_error:
                print(f"CRITICAL: Could not send CFN response: {str(cfn_error)}")
                # Last resort: try with minimal data
                try:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Status': 'FAILED'})
                  print("Minimal FAILED response sent")
                except:
                  print("FATAL: All CFN response attempts failed")
  EnableServicesCustomResource:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: ConfigBucketPolicy  # Ensure Config policy is applied before enabling services
    Properties:
      ServiceToken: !GetAtt EnableServicesLambda.Arn
      PrimaryRegion: !Ref DeploymentRegion
      EnableGuardDuty: !If [EnableGuardDuty, 'true', 'false']
      EnableConfig: !If [EnableConfig, 'true', 'false']
      EnableAWSFoundational: !If [EnableAWSFoundationalPack, 'true', 'false']
      EnableCIS: !If [EnableCISPack, 'true', 'false']
      AWSFoundationalName: !If [EnableAWSFoundationalPack, 'AwsSecurityServicesBestPractices', 'none']
      AWSFoundationalURI: !If [EnableAWSFoundationalPack, !Sub 's3://${ConfigS3BucketName}/conformance-packs/aws-security-services-best-practices.yaml', 'none']
      CISName: !If [EnableCISPack, 'CIS-AWS-Foundations-Benchmark-Level1', 'none']
      CISURI: !If [EnableCISPack, !Sub 's3://${ConfigS3BucketName}/conformance-packs/cis-aws-foundations-benchmark-level1.yaml', 'none']
      BucketName: !Ref ConfigS3BucketName
      ConfigRoleArn: !GetAtt ConfigRole.Arn
      Version: "2.7"  # Fixed CloudTrail permissions for GapRemediation
  GapRemediationLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.12
      Timeout: 30
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse

          def handler(event, context):
            response_data = {'Gaps': []}
            print(f"GapRemediationLambda v2.0 started. Event: {json.dumps(event)}")
            # Version 2.0 - Enhanced error handling and Status field support

            # BULLETPROOF: Always send response, no matter what
            try:
              # Handle DELETE events - just acknowledge deletion
              if event.get('RequestType') == 'Delete':
                print("DELETE request received - acknowledging deletion")
                response_data['Status'] = 'SUCCESS'
                response_data['Message'] = 'Gap remediation resources cleaned up'
                cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
                print("DELETE response sent to CloudFormation")
                return
              s3 = boto3.client('s3')
              iam = boto3.client('iam')
              ec2 = boto3.client('ec2')
              rds = boto3.client('rds')
              ct = boto3.client('cloudtrail')
              gd = boto3.client('guardduty')

              # 1. Public S3 buckets
              buckets = s3.list_buckets()['Buckets']
              for b in buckets:
                try:
                  acl = s3.get_bucket_acl(Bucket=b['Name'])['Grants']
                  if any(g['Grantee']['Type'] == 'Group' and 'AllUsers' in g['Grantee'].get('URI', '') for g in acl):
                    response_data['Gaps'].append(f'Public S3 bucket: {b["Name"]}')
                    s3.put_bucket_public_access_block(
                      Bucket=b['Name'],
                      PublicAccessBlockConfiguration={
                        'BlockPublicAcls': True,
                        'IgnorePublicAcls': True,
                        'BlockPublicPolicy': True,
                        'RestrictPublicBuckets': True
                      }
                    )
                except:
                  pass

              # 2. No MFA on root/users
              summary = iam.get_account_summary()['SummaryMap']
              if summary.get('AccountMFAEnabled', 0) == 0:
                response_data['Gaps'].append('No MFA on root - Manual remediation required')
              users = iam.list_users()['Users']
              for u in users:
                if not iam.list_mfa_devices(UserName=u['UserName'])['MFADevices']:
                  response_data['Gaps'].append(f'No MFA on user: {u["UserName"]} - Manual remediation')

              # 3. Over-permissive IAM policies
              policies = iam.list_policies(Scope='Local')['Policies']
              for p in policies:
                doc = iam.get_policy_version(PolicyArn=p['Arn'], VersionId=p['DefaultVersionId'])['PolicyVersion']['Document']
                if any(s.get('Effect') == 'Allow' and (s.get('Action') == '*' or s.get('Action') == ['*']) for s in doc.get('Statement', [])):
                  response_data['Gaps'].append(f'Over-permissive policy: {p["PolicyName"]} - Review manually')

              # 4. Unencrypted S3 buckets
              for b in buckets:
                try:
                  s3.get_bucket_encryption(Bucket=b['Name'])
                except s3.exceptions.ClientError as e:
                  if e.response['Error']['Code'] == 'ServerSideEncryptionConfigurationNotFoundError':
                    response_data['Gaps'].append(f'Unencrypted S3 bucket: {b["Name"]}')
                    s3.put_bucket_encryption(
                      Bucket=b['Name'],
                      ServerSideEncryptionConfiguration={
                        'Rules': [{'ApplyServerSideEncryptionByDefault': {'SSEAlgorithm': 'AES256'}}]
                      }
                    )

              # 5. Open security groups
              sgs = ec2.describe_security_groups()['SecurityGroups']
              for sg in sgs:
                for rule in sg.get('IpPermissions', []):
                  if rule.get('FromPort') in [22, 3389] and any(ip.get('CidrIp') == '0.0.0.0/0' for ip in rule.get('IpRanges', [])):
                    response_data['Gaps'].append(f'Open security group: {sg["GroupId"]} (port {rule["FromPort"]}) - Manual revoke')

              # 6. Unused IAM credentials
              for u in users:
                access_keys = iam.list_access_keys(UserName=u['UserName'])['AccessKeyMetadata']
                for key in access_keys:
                  last_used = iam.get_access_key_last_used(AccessKeyId=key['AccessKeyId'])['AccessKeyLastUsed']
                  if not last_used.get('LastUsedDate'):
                    response_data['Gaps'].append(f'Unused access key for user: {u["UserName"]} - Deactivate manually')

              # 7. No CloudTrail
              trails = ct.describe_trails()['trailList']
              if not trails:
                response_data['Gaps'].append('No CloudTrail enabled - Already enabling via stack')

              # 8. No GuardDuty
              detectors = gd.list_detectors()['DetectorIds']
              if not detectors:
                response_data['Gaps'].append('No GuardDuty enabled - Already enabling via stack')

              # 9. Public EC2 instances
              instances = ec2.describe_instances()['Reservations']
              for res in instances:
                for inst in res['Instances']:
                  if inst.get('PublicIpAddress'):
                    response_data['Gaps'].append(f'Public EC2 instance: {inst["InstanceId"]} - Make private manually')

              # 10. Unencrypted RDS instances
              dbs = rds.describe_db_instances()['DBInstances']
              for db in dbs:
                if not db.get('StorageEncrypted'):
                  response_data['Gaps'].append(f'Unencrypted RDS instance: {db["DBInstanceIdentifier"]} - Enable encryption manually')

              # Store gap analysis report in organized folder structure
              from datetime import datetime
              timestamp = datetime.utcnow().strftime('%Y-%m-%d_%H-%M-%S')

              s3.put_object(
                Bucket=event['ResourceProperties']['BucketName'],
                Key=f'reports/gap-analysis/gap-report_{timestamp}.json',
                Body=json.dumps(response_data, indent=2)
              )

              # Also create/update latest report for easy access
              s3.put_object(
                Bucket=event['ResourceProperties']['BucketName'],
                Key='reports/gap-analysis/gap-report_latest.json',
                Body=json.dumps(response_data, indent=2)
              )

              # Add Status field for CloudFormation Output reference
              response_data['Status'] = 'SUCCESS'
              print(f"GapRemediation response data: {json.dumps(response_data)}")
              cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
              print("GapRemediation SUCCESS response sent to CloudFormation")

            except Exception as e:
              print(f"GapRemediation top-level error: {str(e)}")
              try:
                cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e), 'Status': 'FAILED'})
                print("GapRemediation FAILED response sent to CloudFormation")
              except Exception as cfn_error:
                print(f"CRITICAL: GapRemediation could not send CFN response: {str(cfn_error)}")
                # Last resort: try with minimal data
                try:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Status': 'FAILED'})
                  print("GapRemediation minimal FAILED response sent")
                except:
                  print("FATAL: GapRemediation all CFN response attempts failed")
  GapRemediationCustomResource:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt GapRemediationLambda.Arn
      BucketName: !Ref ConfigS3BucketName
      Version: "2.7"  # Fixed CloudTrail permissions
    DependsOn: EnableServicesCustomResource
  SNSTopic:
    Type: AWS::SNS::Topic
    Condition: HasSNSEmails
  SNSSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasSNSEmails
    Properties:
      TopicArn: !Ref SNSTopic
      Protocol: email
      Endpoint: !Select [0, !Ref SNSEmails]
  AlertRule:
    Type: AWS::Events::Rule
    Condition: HasSNSEmails
    Properties:
      Description: Alert on HIGH/CRITICAL Security Hub findings
      EventPattern:
        source:
          - aws.securityhub
        detail-type:
          - Security Hub Findings - Imported
        detail:
          findings:
            Severity:
              Label:
                - HIGH
                - CRITICAL
      Targets:
        - Arn: !Ref SNSTopic
          Id: AlertSNS
  AlertRulePermission:
    Type: AWS::SNS::TopicPolicy
    Condition: HasSNSEmails
    Properties:
      Topics:
        - !Ref SNSTopic
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: events.amazonaws.com
            Action: SNS:Publish
            Resource: !Ref SNSTopic
  ExportLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.12
      Timeout: 30
      Code:
        ZipFile: |
          import boto3
          import csv
          from io import StringIO
          import json

          def handler(event, context):
            from datetime import datetime
            sh = boto3.client('securityhub')
            cfg = boto3.client('config')
            s3 = boto3.client('s3')

            # Generate timestamp for monthly report
            timestamp = datetime.utcnow().strftime('%Y-%m')
            bucket_name = event.get('BucketName', 'default-bucket')

            # Generate HIGH/CRITICAL findings report
            findings = sh.get_findings(Filters={'SeverityLabel': [{'Value': 'HIGH', 'Comparison': 'EQUALS'}, {'Value': 'CRITICAL', 'Comparison': 'EQUALS'}]})['Findings']
            csv_buffer = StringIO()
            writer = csv.writer(csv_buffer)
            writer.writerow(['Title', 'Severity', 'Description', 'AWS Account', 'Region', 'Resource ID', 'First Seen', 'Last Seen'])
            for f in findings:
              writer.writerow([
                f.get('Title', 'N/A'),
                f['Severity']['Label'],
                f.get('Description', 'N/A'),
                f.get('AwsAccountId', 'N/A'),
                f.get('Region', 'N/A'),
                f.get('Id', 'N/A'),
                f.get('FirstObservedAt', 'N/A'),
                f.get('UpdatedAt', 'N/A')
              ])

            # Store findings report in organized monthly folder
            s3.put_object(
              Bucket=bucket_name,
              Key=f'reports/monthly/{timestamp}/findings.csv',
              Body=csv_buffer.getvalue()
            )

            # Generate conformance pack compliance report
            packs = cfg.describe_conformance_packs()['ConformancePackDetails']
            compliance_report = {
              'report_date': datetime.utcnow().isoformat(),
              'total_packs': len(packs),
              'conformance_packs': []
            }

            for pack in packs:
              # Get compliance details for each pack
              try:
                compliance = cfg.get_conformance_pack_compliance_summary(
                  ConformancePackName=pack['ConformancePackName']
                )
                pack_info = {
                  'name': pack['ConformancePackName'],
                  'arn': pack['ConformancePackArn'],
                  'last_update': pack['LastUpdateRequestedTime'].isoformat(),
                  'compliance_summary': compliance['ConformancePackComplianceSummary']
                }
              except Exception as e:
                pack_info = {
                  'name': pack['ConformancePackName'],
                  'arn': pack['ConformancePackArn'],
                  'last_update': pack['LastUpdateRequestedTime'].isoformat(),
                  'compliance_summary': f'Error retrieving compliance: {str(e)}'
                }

              compliance_report['conformance_packs'].append(pack_info)

            # Store conformance report in organized monthly folder
            s3.put_object(
              Bucket=bucket_name,
              Key=f'reports/monthly/{timestamp}/conformance-report.json',
              Body=json.dumps(compliance_report, indent=2, default=str)
            )

            # Create summary dashboard report
            summary_report = {
              'report_date': datetime.utcnow().isoformat(),
              'findings_summary': {
                'total_high_critical': len(findings),
                'high_findings': len([f for f in findings if f['Severity']['Label'] == 'HIGH']),
                'critical_findings': len([f for f in findings if f['Severity']['Label'] == 'CRITICAL'])
              },
              'conformance_summary': {
                'total_packs_deployed': len(packs),
                'pack_names': [pack['ConformancePackName'] for pack in packs]
              },
              'report_locations': {
                'detailed_findings': f'reports/monthly/{timestamp}/findings.csv',
                'conformance_details': f'reports/monthly/{timestamp}/conformance-report.json',
                'gap_analysis': 'reports/gap-analysis/gap-report_latest.json'
              }
            }

            s3.put_object(
              Bucket=bucket_name,
              Key=f'reports/monthly/{timestamp}/executive-summary.json',
              Body=json.dumps(summary_report, indent=2, default=str)
            )

            return {'status': 'success', 'reports_generated': 3, 'timestamp': timestamp}
  MonthlyExportRule:
    Type: AWS::Events::Rule
    Properties:
      ScheduleExpression: cron(0 0 1 * ? *)
      Targets:
        - Arn: !GetAtt ExportLambda.Arn
          Id: MonthlyExport
          Input: !Sub '{"BucketName": "${ConfigLogBucket}"}'
  ExportPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt ExportLambda.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt MonthlyExportRule.Arn

Outputs:
  ConfigLogBucketARN:
    Value: !GetAtt ConfigLogBucket.Arn
  CloudTrailLogBucketARN:
    Value: !GetAtt CloudTrailLogBucket.Arn
  SNSTopicARN:
    Value: !If [HasSNSEmails, !Ref SNSTopic, 'No SNS topic created (no emails provided)']
  GapReportURL:
    Value: !Sub https://${ConfigLogBucket}.s3.amazonaws.com/reports/gap-analysis/gap-report_latest.json
  ServiceStatus:
    Value: !GetAtt EnableServicesCustomResource.Status